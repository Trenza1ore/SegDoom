{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import subprocess\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from scipy.signal import lfilter\n",
    "\n",
    "from parse_data.helper_func import load_merged_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_heatmap(pos: np.ndarray, width: int, height: int, radius: int=10, intensity: str=\"linear\"):\n",
    "    f_int = (lambda z: pow(max(radius - z, 0), 2)) if intensity.lower() == \"exponential\" else (lambda z: max(radius - z, 0))\n",
    "    hf_w, hf_h = height // 2 + 1 + 2 * radius, width // 2 + 1 + 2 * radius\n",
    "    hmap = np.zeros((hf_w * 2, hf_h * 2), dtype=np.float64)\n",
    "    offset = np.asfarray([hf_w, hf_h])\n",
    "    ax, ay, az = [], [], []\n",
    "    for i in range(-radius, radius+1):\n",
    "        for j in range(-radius, radius+1):\n",
    "            if (z := np.linalg.norm([i, j])) <= radius:\n",
    "                ax.append(i)\n",
    "                ay.append(j)\n",
    "                az.append(f_int(z))\n",
    "    area = (np.array(ax, dtype=np.int64), np.array(ay, dtype=np.int64), np.array(az, dtype=np.float64))\n",
    "    area_cache = {}\n",
    "\n",
    "    for i in range(pos.shape[0]):\n",
    "        tmp = np.round(pos[i, :2] + offset).astype(int)\n",
    "        p = tuple(tmp.tolist())\n",
    "        if p in area_cache:\n",
    "            hmap[area_cache[p]] += 1\n",
    "        else:\n",
    "            new_entry = area[0] + p[0], area[1] + p[1]\n",
    "            area_cache[p] = new_entry\n",
    "            hmap[new_entry] += area[2]\n",
    "    \n",
    "    return (hmap, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "things_pattern = re.compile(r\"thing // ([0-9]+)\")\n",
    "vertex_pattern = re.compile(r\"vertex // ([0-9]+)\")\n",
    "linedef_pattern = re.compile(r\"linedef // ([0-9]+)\")\n",
    "\n",
    "things_id_map = {\n",
    "    \"ammo\"          : [2007, 2008, 2049],\n",
    "    \"weapon\"        : [2001],\n",
    "    \"medkit\"        : [2012],\n",
    "    \"spawn point\"   : [11],\n",
    "    \"player\"        : [1]\n",
    "}\n",
    "\n",
    "things_marker_def = {\n",
    "    \"ammo\"          : \"s\",\n",
    "    \"weapon\"        : \"X\",\n",
    "    \"medkit\"        : \"P\",\n",
    "    \"spawn point\"   : \"o\",\n",
    "    \"player\"        : \"v\"\n",
    "}\n",
    "\n",
    "things_colour_def = {\n",
    "    \"ammo\"          : \"cyan\",\n",
    "    \"weapon\"        : \"yellow\",\n",
    "    \"medkit\"        : \"orange\",\n",
    "    \"spawn point\"   : \"white\",\n",
    "    \"player\"        : \"k\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_defs = dict()\n",
    "\n",
    "for map_id in range(1, 3+1):\n",
    "    with open(f\"./scenarios/TEXTMAP{map_id}.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "        things = []\n",
    "        verts = {}\n",
    "        edges = []\n",
    "        while line := f.readline():\n",
    "            line = line.lstrip()\n",
    "            if things_pattern.match(line):\n",
    "                x_ = y_ = type_ = None\n",
    "                while line and line[0] != '{':\n",
    "                    line = f.readline().lstrip()\n",
    "                while line and line[0] != '}':\n",
    "                    if line[:2] == 'x ':\n",
    "                        exec(line.replace(\"x = \", \"x_ = \"))\n",
    "                    elif line[:2] == 'y ':\n",
    "                        exec(line.replace(\"y = \", \"y_ = \"))\n",
    "                    elif line[:5] == 'type ':\n",
    "                        exec(line.replace(\"type = \", \"type_ = \"))\n",
    "                    line = f.readline().lstrip()\n",
    "                things.append((x_, y_, type_))\n",
    "            elif match := vertex_pattern.match(line):\n",
    "                x_ = y_ = None\n",
    "                while line and line[0] != '{':\n",
    "                    line = f.readline().lstrip()\n",
    "                while line and line[0] != '}':\n",
    "                    if line[:2] == 'x ':\n",
    "                        exec(line.replace(\"x = \", \"x_ = \"))\n",
    "                    elif line[:2] == 'y ':\n",
    "                        exec(line.replace(\"y = \", \"y_ = \"))\n",
    "                    line = f.readline().lstrip()\n",
    "                verts[int(match.group(1))] = (x_, y_)\n",
    "            elif linedef_pattern.match(line):\n",
    "                v1 = v2 = None\n",
    "                while line and line[0] != '{':\n",
    "                    line = f.readline().lstrip()\n",
    "                while line and line[0] != '}':\n",
    "                    if line[:2] == 'v1':\n",
    "                        exec(line)\n",
    "                    elif line[:2] == 'v2':\n",
    "                        exec(line)\n",
    "                    line = f.readline().lstrip()\n",
    "                v1x, v1y = verts[v1]\n",
    "                v2x, v2y = verts[v2]\n",
    "                edges.append(((v1x, v2x), (v1y, v2y)))\n",
    "\n",
    "    id_things_map = {}\n",
    "    for k, v in things_id_map.items():\n",
    "        for i in v:\n",
    "            id_things_map[i] = k\n",
    "    things_dict = {i : [] for i in things_id_map.keys()}\n",
    "    for tx, ty, tid in things:\n",
    "        things_dict[id_things_map[tid]].append([tx, ty])\n",
    "    things_dict = {k : np.array(v).T for k, v in things_dict.items()}\n",
    "\n",
    "    map_defs[map_id] = (things_dict, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {m.split(os.path.sep)[-1] : {} for m in glob.glob(\"logs/*map*\")}\n",
    "names_to_eval = {\"r1_r_sl_ss_5e-4\", \"r1_r_Dsl_ss_5e-4\", \"ss_1e-3\", \"s4_ss_1e-3\", \"rgb_9e-4\", \"ss_rgb_1e-3_best\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating heatmap: rtss_map3/s4_ss_1e-3_5e-4t4\r"
     ]
    }
   ],
   "source": [
    "hmap_res = 10\n",
    "for map_name, map_dict in all_results.items():\n",
    "    all_models = [m.split(os.path.sep)[-1] for m in glob.glob(f\"logs/{map_name}/*\")]\n",
    "    for m in all_models:\n",
    "        m_cleaned = m.strip('_').replace(\"ppo_\", '').replace(\"_final\", '')\n",
    "        if m_cleaned not in names_to_eval:\n",
    "            continue\n",
    "        path_ = f\"logs/{map_name}/{m}/record_*.npz\"\n",
    "        if glob.glob(path_):\n",
    "            _, pos, _, wpn, fps, miou = load_merged_records(f\"logs/{map_name}/{m}/record_*.npz\", load_obs=False, no_tqdm=True)\n",
    "            print(f\"Generating heatmap: {map_name}/{m_cleaned}\", end='\\r')\n",
    "            size_width, size_height = (2000, 2000) if \"map3\" in map_name else (1440, 1440)\n",
    "            hmap = agent_heatmap(pos, size_width, size_height, hmap_res, \"linear\")\n",
    "            map_dict[m_cleaned] = dict(pos=pos, wpn=wpn, fps=fps, miou=miou, hmap=hmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map: map1  | Model: r1_r_sl_ss_5e-4            | MIoU : 0.993 +/- 0.0008\n",
      "Map: map1  | Model: s4_ss_1e-3                 | MIoU : 0.994 +/- 0.0004\n",
      "Map: map1a | Model: ss_rgb_1e-3_best           | MIoU : 0.982 +/- 0.0009\n",
      "Map: map1w | Model: ss_rgb_1e-3_best           | MIoU : 0.983 +/- 0.0008\n",
      "Map: map2s | Model: r1_r_Dsl_ss_5e-4           | MIoU : 0.982 +/- 0.0006\n",
      "Map: map3  | Model: r1_r_sl_ss_5e-4            | MIoU : 0.985 +/- 0.0019\n",
      "Map: map3  | Model: s4_ss_1e-3                 | MIoU : 0.982 +/- 0.0026\n"
     ]
    }
   ],
   "source": [
    "for map_name, map_dict in all_results.items():\n",
    "    for model, model_dict in map_dict.items():\n",
    "        miou = map_dict[model][\"miou\"]\n",
    "        if isinstance(miou, np.ndarray):\n",
    "            print(f\"Map: {map_name[5:]:5s} | Model: {model:26s} | MIoU : {miou.mean():5.3f} +/- {miou.std():6.4f}\")\n",
    "            # print(map_name, model, miou.min(), miou.max(), miou.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"heatmaps.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_results, f)\n",
    "\n",
    "with open(\"mapdefs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(map_defs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
