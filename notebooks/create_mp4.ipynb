{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import shutil\n",
    "import subprocess\n",
    "import concurrent.futures\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "from stats import DiscordWebhook\n",
    "from parse_data.helper_func import load_merged_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_padding_time = 2                # Number of seconds to repeat for the last frame\n",
    "fps = 35                            # Frame rate, 35 for Doom's default settings\n",
    "cmap = cm.jet                       # Colour map for semantic segmentation\n",
    "save_path = \"captures/media\"        # Directory to save videos\n",
    "tmp_path = f\"{save_path}/tmp\"       # Directory to save temporary images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NVENC is faster & on GPU but often less optimized in file size\n",
    "conversion_command = f\"ffmpeg -framerate {fps} -i %s -c:v libx264 -crf 21 -preset fast -f mp4 -pix_fmt yuv420p %s\"\n",
    "# conversion_command = f\"ffmpeg -framerate {fps} -hwaccel_output_format cuda -i %s -c:v h264_nvenc -crf 21 -preset fast -f mp4 -pix_fmt yuv420p %s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pillow_frames(last_ep_end: int, ep: int, obs: np.ndarray, img_type: str=\"rs\", \n",
    "                         scale: int=0) -> list[Image.Image]:\n",
    "    frames = []\n",
    "    for i in range(last_ep_end, ep):\n",
    "        img = []\n",
    "        for c in img_type:\n",
    "            if c == 'r':\n",
    "                img.append(obs[i, :3, :, :].transpose(1, 2, 0))\n",
    "            elif c == 's':\n",
    "                img.append(np.array(cmap(obs[i, 3, :, :])[:, :, :3] * 255, dtype=np.uint8))\n",
    "        if len(img) == 1:\n",
    "            img = img[0]\n",
    "        else:\n",
    "            img = np.concatenate(img)\n",
    "        if scale:\n",
    "            img = np.repeat(np.repeat(img, repeats=scale, axis=0), repeats=scale, axis=1)\n",
    "        frames.append(Image.fromarray(img))\n",
    "    frames += [frames[-1]] * (fps * end_padding_time).__ceil__()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_subprocess_call(cmd: str) -> subprocess.CompletedProcess:\n",
    "    return subprocess.run(cmd, shell=True)\n",
    "\n",
    "def t_render(last_ep_end: int, ep: int, obs: np.ndarray, score: int, save_name: str, \n",
    "             ep_num: int, tmp_n_digits: int|str, img_type: str=\"rs\", scale: int=0) -> subprocess.CompletedProcess:\n",
    "    frames = create_pillow_frames(last_ep_end, ep, obs, img_type, scale)\n",
    "\n",
    "    tmp_template = f\"{tmp_path}/{ep_num}_%0{tmp_n_digits}d.png\"\n",
    "\n",
    "    for i, img in enumerate(frames):\n",
    "        img.save(tmp_template %i)\n",
    "    \n",
    "    mp4_path = f\"{save_name}_ep{ep_num:03d}_{score}.mp4\"\n",
    "    if os.path.exists(mp4_path):\n",
    "        os.remove(mp4_path)\n",
    "    \n",
    "    del img\n",
    "    gc.collect()\n",
    "\n",
    "    cmd = conversion_command % (tmp_template, mp4_path)\n",
    "    return subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_as_mp4(pool: concurrent.futures.ThreadPoolExecutor, obs: np.ndarray, ep_ends: np.ndarray, \n",
    "                  scores: np.ndarray, save_name: str, img_type: str=\"rs\", parallelize: str=\"pillow\", \n",
    "                  scale: int=0) -> dict[concurrent.futures.Future, int]:\n",
    "    # We only know how many digits to reserve for temporary images at run time\n",
    "    tmp_n_digits = str(len(str(obs.shape[0])))\n",
    "\n",
    "    last_ep_end = 0\n",
    "    worker_jobs = {}\n",
    "\n",
    "    try:\n",
    "        if os.path.exists(tmp_path):\n",
    "            shutil.rmtree(tmp_path)\n",
    "        os.makedirs(tmp_path)\n",
    "    except:\n",
    "        print(f\"Failed attempt at cleaning tmp directory, consider manual cleaning later\")\n",
    "    \n",
    "    num_eps = ep_ends.shape[0]\n",
    "\n",
    "    first_pass = parallelize in {\"ffmpeg\", \"pillow\"}\n",
    "\n",
    "    for ep_num, ep in (pbar := tqdm(enumerate(ep_ends.tolist(), 1), total=num_eps, ncols=100, leave=True, \n",
    "                                    desc=\"rendering ep 1\" if first_pass else \"submitting jobs\")):\n",
    "        score = int(scores[ep_num-1]) if len(scores) else ''\n",
    "        pbar.update(0)\n",
    "        match parallelize:\n",
    "            case \"ffmpeg\":\n",
    "                frames = create_pillow_frames(last_ep_end, ep, obs, img_type, scale)\n",
    "\n",
    "                pbar.set_description(f\"saving ep {ep_num}\")\n",
    "                tmp_template = f\"{tmp_path}/{ep_num}_%0{tmp_n_digits}d.png\"\n",
    "                for i, img in enumerate(frames):\n",
    "                    img.save(tmp_template %i)\n",
    "                \n",
    "                pbar.set_description(f\"converting ep {ep_num}\")\n",
    "                mp4_path = f\"{save_name}_ep{ep_num:03d}_{score}.mp4\"\n",
    "                if os.path.exists(mp4_path):\n",
    "                    os.remove(mp4_path)\n",
    "\n",
    "                cmd = conversion_command % (tmp_template, mp4_path)\n",
    "                worker_jobs[pool.submit(t_subprocess_call, cmd)] = ep_num\n",
    "            case \"pillow\":\n",
    "                frames = create_pillow_frames(last_ep_end, ep, obs, img_type, scale)\n",
    "                \n",
    "                pbar.set_description(f\"saving ep {ep_num}\")\n",
    "                tmp_template = f\"{tmp_path}/{ep_num}_%0{tmp_n_digits}d.png\"\n",
    "\n",
    "                current_jobs = {\n",
    "                    pool.submit(img.save, tmp_template %i) : (ep_num, i) for i, img in enumerate(frames)\n",
    "                }\n",
    "                worker_jobs.update(current_jobs)\n",
    "                \n",
    "                pbar.set_description(f\"converting ep {ep_num}\")\n",
    "                mp4_path = f\"{save_name}_ep{ep_num:03d}_{score}.mp4\"\n",
    "                if os.path.exists(mp4_path):\n",
    "                    os.remove(mp4_path)\n",
    "\n",
    "                cmd = conversion_command % (tmp_template, mp4_path)\n",
    "\n",
    "                concurrent.futures.wait(current_jobs)\n",
    "                worker_jobs[pool.submit(t_subprocess_call, cmd)] = ep_num\n",
    "            case \"all\":\n",
    "                worker_jobs[pool.submit(t_render, last_ep_end, ep, obs, score, save_name, ep_num, tmp_n_digits, img_type, scale)] = ep_num\n",
    "            case _:\n",
    "                raise NotImplementedError(f\"Unknown parallelization option: \\\"{parallelize}\\\"\")\n",
    "\n",
    "        last_ep_end = ep + 1\n",
    "        \n",
    "        if ep_num != num_eps:\n",
    "            pbar.set_description(f\"rendering ep {ep_num+1}\")\n",
    "        else:\n",
    "            pbar.set_description(\"rendering done\")\n",
    "    \n",
    "    for job in tqdm(concurrent.futures.as_completed(worker_jobs), ncols=100,\n",
    "                    total=len(worker_jobs), desc=\"finishing up\"):\n",
    "        job.result()\n",
    "    \n",
    "    try:\n",
    "        if os.path.exists(tmp_path):\n",
    "            shutil.rmtree(tmp_path)\n",
    "    except:\n",
    "        print(f\"Failed attempt at cleaning tmp directory, consider manual cleaning later\")\n",
    "\n",
    "    return worker_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_names = []\n",
    "for i in range(1, 3+1):\n",
    "    base_name = \"map\" + str(i)\n",
    "    map_variants = [base_name, \"rtss_\" + base_name]\n",
    "    for v in \"saw\":\n",
    "        map_variants.append(base_name + v)\n",
    "        map_variants.append(f\"rtss_{base_name}{v}\")\n",
    "    map_names.extend(map_variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_all_mp4s_of_model(pool: concurrent.futures.ThreadPoolExecutor, model_name: str, model_dir: str, scale: int=0,\n",
    "                             map_names: list[str]=map_names, img_type: str=\"rs\", parallelize: str=\"pillow\") -> list[str]:\n",
    "    success = []\n",
    "    for map_name in map_names:\n",
    "        record_path = f\"captures/{map_name}/{model_dir}/record_*.npz\"\n",
    "        if glob.glob(record_path):\n",
    "            print(f\"Loading {model_name}/{map_name}...\", flush=True, end='\\r')\n",
    "            try:\n",
    "                map_name_save = map_name\n",
    "                sub_dir = '' if img_type == \"rs\" else f\"/{img_type.replace('r', \"rgb_\").replace('s', \"ss_\").strip('_')}\"\n",
    "                if map_name.startswith(\"rtss_\"):\n",
    "                    map_name_save = map_name[5:]\n",
    "                    save_name = f\"{save_path}/{model_name.replace('ss', 'rtss')}{sub_dir}/{map_name_save}/\"\n",
    "                else:\n",
    "                    save_name = f\"{save_path}/{model_name}{sub_dir}/{map_name_save}/\"\n",
    "                if os.path.isdir(save_name) and os.listdir(save_name):\n",
    "                    print(f\"Already done: {model_name}/{map_name}\", flush=True, end='\\n')\n",
    "                    continue\n",
    "                if not os.path.isdir(save_name):\n",
    "                    os.makedirs(save_name)\n",
    "                save_name += f\"{model_name}_{map_name_save}\"\n",
    "                obs, _, ep_ends, *_, scores = load_merged_records(record_path, load_pos=False, no_tqdm=True)\n",
    "                gc.collect()\n",
    "                t = time.time()\n",
    "                DiscordWebhook.send_msg_no_instance(f\"mp4 creation job of {model_name}/{map_name} ({img_type}) starts\")\n",
    "                print(f\"Rendering {model_name}/{map_name}...\", flush=True, end='\\r')\n",
    "                render_as_mp4(pool, obs, ep_ends, scores, save_name, img_type, parallelize, scale)\n",
    "                t = round(time.time() - t)\n",
    "                DiscordWebhook.send_msg_no_instance(f\"mp4 creation job of {model_name}/{map_name} ({img_type}) done, took {t//60} min {t%60} sec\")\n",
    "                success.append(map_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Loading {model_name}/{map_name} failed\", flush=True, end='\\n')\n",
    "                DiscordWebhook.send_msg_no_instance(f\"mp4 creation job of {model_name}/{map_name} ({img_type}) failed\")\n",
    "                DiscordWebhook.send_error_no_instance(e)\n",
    "            finally:\n",
    "                gc.collect()\n",
    "    DiscordWebhook.send_msg_no_instance(f\"All mp4 creation jobs of {model_name} ({img_type}) done!\")\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already done: ppo_ss_rgb/map1\n",
      "Already done: ppo_ss_rgb/rtss_map1\n",
      "Already done: ppo_ss_rgb/rtss_map1a\n",
      "Already done: ppo_ss_rgb/rtss_map1w\n",
      "Already done: ppo_ss_rgb/map2s\n",
      "Already done: ppo_ss_rgb/rtss_map2s\n",
      "Rendering ppo_ss_4/map1...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rendering done: 100%|███████████████████████████████████████████████| 20/20 [02:39<00:00,  7.95s/it]\n",
      "finishing up: 100%|███████████████████████████████████████▉| 98286/98288 [00:07<00:00, 10637.97it/s]"
     ]
    }
   ],
   "source": [
    "# Pillow's png saving is the bottleneck here, parallelizing it is significantly faster \n",
    "# (8x on my device)\n",
    "# parallelize, max_workers = \"all\", None\n",
    "parallelize, max_workers = \"pillow\", None\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as pool:\n",
    "    render_all_mp4s_of_model(pool, \"ppo_ss_rgb\", \"ppo_ss_rgb_1e-3_best\", img_type=\"rs\", parallelize=parallelize)\n",
    "    render_all_mp4s_of_model(pool, \"ppo_ss_4\", \"s4_ppo_ss_1e-3_final\", img_type=\"s\", parallelize=parallelize)\n",
    "    render_all_mp4s_of_model(pool, \"ppo_rgb\", \"rgb_9e-4_\", img_type=\"r\", parallelize=parallelize)\n",
    "    render_all_mp4s_of_model(pool, \"ppo_ss_4\", \"s4_ppo_ss_1e-3_final\", img_type=\"rs\", parallelize=parallelize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(tmp_path):\n",
    "    shutil.rmtree(tmp_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
